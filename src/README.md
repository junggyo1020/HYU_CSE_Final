TAACO와 TASSC에서는 개별 텍스트 데이터를 전부 한 텍스트 파일에 모아서 분석하면, 텍스트의 응집성과 다양성 평가에서 의도치 않은 결과를 낳게 됨.
예를 들어서 설명하면, CNN의 경우 각각의 기사에서, 기사의 원문과 요약문이 얼마나 잘 응집되어 있는 지(유사한지), 한 기사 안에서 얼마나 다양한
어휘들이 사용되었는 지를 평가하는 것이 중요함. 그러나, 이러한 평가를 위해서는 각각의 기사를 개별적으로 분석해야 함. 그렇기 때문에 데이터들을
개별의 텍스트로 분리하여 저장해야 함.

데이터셋을 1%만 사용했는데도, main.py에서만 1분 이상의 시간이 소요됨. 이후 교수님께서 자동화에 대해 지적한다면, TAACO와 TASSC을 수정하여
자동화를 진행할 예정임.

수정 전, 기존의 WMT에 대한 평가의 결과 점수가 낮게 나온 이유는, BERT를 포함한 평가 지표들은 일반적으로 같은 언어 데이터에 대해서 유사성을
평가하는 것이기 때문임. 그러나, 기존의 코드에서는 다른 언어에 대한 번역을 평가하는 것이기 때문에, 점수가 낮게 나온 것임. 이를 해결하기 위해서,
기존의 코드를 수정하여, 번역된 데이터에 대한 평가(독일어로 번역된 WMT의 영어와 WMT의 독일어를 비교)를 진행함. 그런데 BLEU와 Combined Score
의 점수는 5배 가까이 높아졌지만, 다른 지표들의 값은 전혀 변하지 않았음. 이유는 아직 모르겠음.